{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News (Show/Ask)\n",
    "\n",
    "In this project I'll be going over the show and ask section on hacker news and try to determine which of the two attracts more comments in general, and of all posts that receive atleast one comment. Also, attempt to answer if there is an optimal time to post to hacker news to gain the most amount of traction.\n",
    "\n",
    "To start - we'll need to read into our csv file which is stored in the same directory as this file and named `'Hacker_News2016.csv'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "file = open('Hacker_News2016.csv', encoding='utf-8')\n",
    "hn = list(reader(file))\n",
    "\n",
    "hn_header, hn_data =  hn[0], hn[1:] # splits data into its header and data portions\n",
    "\n",
    "for data in hn_data[:3]:\n",
    "    print(data) # displays the first few rows so we get a feel as to what the data looks like\n",
    "    print()\n",
    "    \n",
    "print('\\n')\n",
    "hn_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293119"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hn_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset nearly contains 300,000 individual post data. Because this analysis only cares about whether the post is a ask/show hn post we'll have to filter this down.\n",
    "\n",
    "- `ask_hn_posts` - all posts that contains 'ask hn' in the title\n",
    "- `show_hn_posts` - all posts that contains 'show hn' in the title\n",
    "- `other_posts` - everything else\n",
    "\n",
    "while we don't need to include `other_posts` it may be useful later down the line to explore the dataset in another way.\n",
    "\n",
    "Another thing we care about is whether or not a post has a comment, these will be filtered as,\n",
    "`ask_hn_plus_comments` and `show_hn_plus_comments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "ask_hn_posts = []\n",
    "ask_hn_plus_comments = []\n",
    "show_hn_posts = []\n",
    "show_hn_plus_comments = []\n",
    "other_posts = []\n",
    "other_plus_comments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in hn_data:\n",
    "    title = post[1].lower()\n",
    "    try:\n",
    "        num_comments = int(post[4])\n",
    "    except:\n",
    "        num_comments = 0\n",
    "        \n",
    "    if title.startswith('ask hn'):\n",
    "        ask_hn_posts.append(post)\n",
    "        if num_comments > 0:\n",
    "            ask_hn_plus_comments.append(post)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_hn_posts.append(post)\n",
    "        if num_comments > 0:\n",
    "            show_hn_plus_comments.append(post)\n",
    "    else:\n",
    "        other_posts.append(post)\n",
    "        if num_comments > 0:\n",
    "            other_plus_comments.append(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASK: 9139\n",
      "ASK W/ COMMENTS: 6911\n",
      "\n",
      "SHOW: 10158\n",
      "SHOW W/ COMMENTS: 5059\n",
      "\n",
      "OTHER: 273822\n",
      "OTHER W/ COMMENTS: 68431\n"
     ]
    }
   ],
   "source": [
    "print('ASK:', len(ask_hn_posts))\n",
    "print('ASK W/ COMMENTS:', len(ask_hn_plus_comments))\n",
    "print()\n",
    "print('SHOW:', len(show_hn_posts))\n",
    "print('SHOW W/ COMMENTS:', len(show_hn_plus_comments))\n",
    "print()\n",
    "print('OTHER:', len(other_posts))\n",
    "print('OTHER W/ COMMENTS:', len(other_plus_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we have now reduced our data set from 300,000 to 20,000(12,000 if we only care about posts with comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our newly filtered data we can perform some basic analysis on it. <br> <br>\n",
    "\n",
    "Let's try to answer the following questions:\n",
    "- What is the average number of comments on a ask post?\n",
    "- What is the average number of comments on a show post?\n",
    "- Average for ask posts with 1 or more comments?\n",
    "- Average for show posts with 1 more more comments?\n",
    "<br><br>\n",
    "To do this, we first loop through our `ask_hn_posts` and `show_hn_posts` and extract the num_comments column out (5 -> index 4), convert it into an integer and then add that value to the `ask_posts_avg`or `show_posts_average` then take the average. (`ask_plus_comments_avg` and `show_plus_comments_avg` for posts with comments). \n",
    "<br><br>\n",
    "There are many ways to take the average of something, but the way we're going to use is to initialize our variables as a list, sum up all the values in that list using the built-in `sum()` function, and then divide the sum by the length of that list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather values\n",
    "def gather_comments_avg(dataset, col, cond=lambda x: True):\n",
    "    avg_s1 = []\n",
    "    for data in dataset:\n",
    "        val = data[col]\n",
    "        try:\n",
    "            val = int(val)\n",
    "        except:\n",
    "            val = 0\n",
    "            \n",
    "        if cond(val):\n",
    "            avg_s1.append(val)\n",
    "            \n",
    "    avg_s2 = sum(avg_s1) / len(avg_s1)\n",
    "    return avg_s2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASK AVERAGE 10.39\n",
      "ASK AVERAGE+ 13.74\n",
      "\n",
      "SHOW AVERAGE 4.89\n",
      "SHOW AVERAGE+ 9.81\n"
     ]
    }
   ],
   "source": [
    "# averages\n",
    "ask_posts_avg = gather_comments_avg(ask_hn_posts, 4)\n",
    "show_posts_average = gather_comments_avg(show_hn_posts, 4)\n",
    "ask_plus_comments_avg = gather_comments_avg(ask_hn_plus_comments, 4)\n",
    "show_plus_comments_avg = gather_comments_avg(show_hn_plus_comments, 4)\n",
    "\n",
    "print(f'ASK AVERAGE {ask_posts_avg:.2f}')\n",
    "print(f'ASK AVERAGE+ {ask_plus_comments_avg:.2f}')\n",
    "print()\n",
    "print(f'SHOW AVERAGE {show_posts_average:.2f}')\n",
    "print(f'SHOW AVERAGE+ {show_plus_comments_avg:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask posts receive an average of 10.4(13.7 for comments >= 1) comments while show posts only receive an average of 4.89(9.81 for comments >= 1). <br>\n",
    "\n",
    "With this information we can conclude to our first question 'whether ask or show posts receive more comments', that ask posts receive more comments on average. Which makes sense considering 'ask' is like a request for information rather than something you show to people, where people may or may not have an opinion of the thing being shown. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next portion of our analysis will be focused on the time frame in which a post is published and the comments it receives, so with this in mind we'll be focusing on the `ask_hn_plus_comments` dataset.<br><br>\n",
    "We'll first extract the date created and the number of comments from each datapoint into a list. Then we'll parse the list and create a dictionary for each hour of the day, incrementing the stored value of each hour by 1 each time we pass a value in our list created during that specific hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12571287',\n",
       " \"Ask HN: What's the best way to learn about the blockchain?\",\n",
       " '',\n",
       " '247',\n",
       " '66',\n",
       " 'm52go',\n",
       " '9/24/2016 15:29']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_hn_plus_comments[20] # to avoid scrolling up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_numcomments = []\n",
    "hours_dict = {}\n",
    "comments_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "for post in ask_hn_plus_comments:\n",
    "    date = post[6]\n",
    "    date_time = datetime.datetime.strptime(date, '%m/%d/%Y %H:%M')\n",
    "    num_comments = int(post[4]) # validated earlier\n",
    "    created_numcomments.append([date_time, num_comments])\n",
    "\n",
    "for date, comments in created_numcomments:\n",
    "    if date.hour in hours_dict:\n",
    "        hours_dict[date.hour] += 1\n",
    "    else:\n",
    "        hours_dict[date.hour] = 1\n",
    "        \n",
    "    if date.hour in comments_dict:\n",
    "        comments_dict[date.hour] += comments\n",
    "    else:\n",
    "        comments_dict[date.hour] = comments\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following uses the two previously defined dictionaries and creates a list of lists containing the hour and the average number of comments for that hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_posts_per_hour = []\n",
    "\n",
    "for idx in range(len(hours_dict)):\n",
    "    posts = hours_dict[idx]\n",
    "    comments = comments_dict[idx]\n",
    "    average_posts_per_hour.append([idx, comments / posts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_posts_per_hour = [[val[1], val[0]] for val in average_posts_per_hour] # flipping the values around\n",
    "average_posts_per_hour = sorted(average_posts_per_hour, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've established the number of comments for each hour, let's display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE NUMBER OF COMMENTS FOR EACH HOUR SORTED FROM GREATEST TO LEAST AMOUNT OF COMMENTS.\n",
      "15:00 - AVG Comments: 39.67\n",
      "13:00 - AVG Comments: 22.22\n",
      "12:00 - AVG Comments: 15.45\n",
      "10:00 - AVG Comments: 13.76\n",
      "17:00 - AVG Comments: 13.73\n",
      "2:00 - AVG Comments: 13.20\n",
      "14:00 - AVG Comments: 13.15\n",
      "4:00 - AVG Comments: 12.69\n",
      "8:00 - AVG Comments: 12.43\n",
      "22:00 - AVG Comments: 11.75\n",
      "20:00 - AVG Comments: 11.38\n",
      "11:00 - AVG Comments: 11.14\n",
      "5:00 - AVG Comments: 11.14\n",
      "21:00 - AVG Comments: 11.06\n",
      "18:00 - AVG Comments: 10.79\n",
      "16:00 - AVG Comments: 10.76\n",
      "3:00 - AVG Comments: 10.16\n",
      "7:00 - AVG Comments: 10.10\n",
      "0:00 - AVG Comments: 9.86\n",
      "19:00 - AVG Comments: 9.41\n",
      "1:00 - AVG Comments: 9.37\n",
      "6:00 - AVG Comments: 9.02\n",
      "9:00 - AVG Comments: 8.39\n",
      "23:00 - AVG Comments: 8.32\n"
     ]
    }
   ],
   "source": [
    "print('AVERAGE NUMBER OF COMMENTS FOR EACH HOUR SORTED FROM GREATEST TO LEAST AMOUNT OF COMMENTS.')\n",
    "for comments, hour in average_posts_per_hour:\n",
    "    print(f'{hour}:00 - AVG Comments: {comments:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we see that to gain the most amount of comments we should post an ask hn at 15:00 or 3pm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
